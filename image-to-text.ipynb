{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/supriyasindigerekumaraswmamy/Desktop/Thesis/Hugging-face-models/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-29 21:12:15.711814: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import find_dotenv,load_dotenv\n",
    "from transformers import pipeline\n",
    "\n",
    "import warnings\n",
    "\n",
    "import requests\n",
    "import os\n",
    "load_dotenv(find_dotenv())\n",
    "warnings.filterwarnings('ignore')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2text(url):\n",
    "    pipe=pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-large\")\n",
    "    text = pipe(url)[0]['generated_text']\n",
    "    print(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a screenshot of a computer screen with a graph and a bar chart\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "image=img2text('dataset.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a screenshot of a computer screen with a graph and a bar chart'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate story using LLAMA3 for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def generate_story(scenario):\n",
    "    prompt = f\"\"\"You are a storyteller;\n",
    "Generate a short story based on the {scenario} in less than 30 words;\n",
    "Use the below output format;\n",
    "\n",
    "context: {scenario}\n",
    "Story:\n",
    "\"\"\"\n",
    "    response = ollama.chat(model='llama3', options={'temperature': 1}, messages=[{\n",
    "        'role': 'user',\n",
    "        'content': prompt,\n",
    "    }])\n",
    "    story = response['message']['content']\n",
    "    print(story)\n",
    "    return story\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a short story based on the screenshot:\n",
      "\n",
      "**Context:** A screenshot of a computer screen with a graph and a bar chart\n",
      "\n",
      "**Story:** The numbers told a tale of triumph. Dr. Patel's research on patient outcomes revealed a sharp spike in successful treatments after implementing her innovative therapy protocol. As she gazed at the bar chart, a smile spread across her face, knowing her hard work was paying off.\n"
     ]
    }
   ],
   "source": [
    "story = generate_story(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2speech(message,api_token):\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/espnet/kan-bayashi_csmsc_conformer_fastspeech2\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_token}\"} \n",
    "    payloads = {\n",
    "        'inputs': message\n",
    "    }\n",
    " \n",
    "    response = requests.post(API_URL, headers=headers, json=payloads)\n",
    "    if response.status_code == 200:\n",
    "        with open('audio.flac', 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(\"Audio file created successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.json())\n",
    "   ### with open ('audio.mp3','wb') as file:\n",
    "        #file.write(response.content)\n",
    "    #return response.content\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a short story based on the given screenshot:\\n\\n**Context:**\\n\\n\\nA simple graph displays a steady incline, as if it\\'s tracking a journey. A bar chart alongside shows a series of milestones marked \"Project X Completion\", each one representing a significant step forward.\\n\\n**Story:**\\n\\nAs I gazed at the screen, memories flooded back to that fateful night when our team finally wrapped up Project X. The graph represented our collective effort â€“ steady and consistent like our determination. And those bar chart markers? Each one told a story of triumph over obstacles, until the final hurdle was cleared. That moment, frozen in digital eternity, still gave me goosebumps.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "text2speech(story,HUGGINGFACEHUB_API_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"img 2 story\")\n",
    "    st.header(\"Turn image into a story\")\n",
    "    uploaded_file=st.file_uploader(\"Choose an image...\",type=\"jpg\")\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        print(uploaded_file)\n",
    "        bytes_data =uploaded_file.getvalue()\n",
    "        with open(uploaded_file.name, 'wb')as file:\n",
    "            file.write(bytes_data)\n",
    "        st.image(uploaded_file,caption='Uploaded image.',use_column_width=True)\n",
    "        scenario=img2text(uploaded_file.name)\n",
    "        story =generate_story(scenario)\n",
    "        text2speech(story)\n",
    "\n",
    "        with st.expander(\"scenario\"):\n",
    "            st.write(scenario)\n",
    "        with st.expander(\"story\"):\n",
    "            st.write(story)\n",
    "\n",
    "        st.audio(\"audio.flac\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ =='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
